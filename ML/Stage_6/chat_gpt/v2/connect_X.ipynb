{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UICxB_OdX7Rn"
   },
   "source": [
    "# Create our environment (connect-4 game)\n",
    "\n",
    "Connect-4 is a game in which if one were to connect 4 of his moves either horizontally, vertically or diagonally, one records a win. In reinforcement learning setting, we grant reward = 1 for a win, -1 for a lose and 0.5 for a draw. The following game engine object provides five methods.\n",
    "* Render :  \n",
    "       Showing the board state with X and Os.\n",
    "* Reset : \n",
    "       For playing over and over.\n",
    "* Get available moves : \n",
    "       Scan the board state and give available moves.\n",
    "* Check game done : \n",
    "       Based on which player is making the move, check if one has won the game or a draw has resulted.\n",
    "* Make move : \n",
    "       Record the move by players and return observation and reward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "c8VjyWDXX7Rp"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "\n",
    "class connect_x:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.board_height = 6\n",
    "        self.board_width = 7\n",
    "        self.board_state = np.zeros([self.board_height, self.board_width], dtype=np.int8)\n",
    "        self.players = {'p1': 1, 'p2': 2}\n",
    "        self.isDone = False\n",
    "        self.reward = {'win': 1, 'draw': 0.5, 'lose': -1}\n",
    "    \n",
    "    def render(self):\n",
    "        rendered_board_state = self.board_state.copy().astype(np.str)\n",
    "        rendered_board_state[self.board_state == 0] = ' '\n",
    "        rendered_board_state[self.board_state == 1] = 'O'\n",
    "        rendered_board_state[self.board_state == 2] = 'X'\n",
    "        display(pd.DataFrame(rendered_board_state))\n",
    "    \n",
    "    def reset(self):\n",
    "        self.__init__()\n",
    "        \n",
    "    def get_available_actions(self):\n",
    "        available_cols = []\n",
    "        for j in range(self.board_width):\n",
    "            if np.sum([self.board_state[:, j] == 0]) != 0:\n",
    "                available_cols.append(j)\n",
    "        return available_cols\n",
    "    \n",
    "    def check_game_done(self, player):\n",
    "        if player == 'p1':\n",
    "            check = '1 1 1 1'\n",
    "        else:\n",
    "            check = '2 2 2 2'\n",
    "        \n",
    "        # check vertically then horizontally\n",
    "        for j in range(self.board_width):\n",
    "            if check in np.array_str(self.board_state[:, j]):\n",
    "                self.isDone = True\n",
    "        for i in range(self.board_height):\n",
    "            if check in np.array_str(self.board_state[i, :]):\n",
    "                self.isDone = True\n",
    "        \n",
    "        # check left diagonal and right diagonal\n",
    "        for k in range(0, self.board_height - 4 + 1):\n",
    "            left_diagonal = np.array([self.board_state[k + d, d] for d in \\\n",
    "                            range(min(self.board_height - k, min(self.board_height, self.board_width)))])\n",
    "            right_diagonal = np.array([self.board_state[d + k, self.board_width - d - 1] for d in \\\n",
    "                            range(min(self.board_height - k, min(self.board_height, self.board_width)))])\n",
    "            if check in np.array_str(left_diagonal) or check in np.array_str(right_diagonal):\n",
    "                self.isDone = True\n",
    "        for k in range(1, self.board_width - 4 + 1):\n",
    "            left_diagonal = np.array([self.board_state[d, d + k] for d in \\\n",
    "                            range(min(self.board_width - k, min(self.board_height, self.board_width)))])\n",
    "            right_diagonal = np.array([self.board_state[d, self.board_width - 1 - k - d] for d in \\\n",
    "                            range(min(self.board_width - k, min(self.board_height, self.board_width)))])\n",
    "            if check in np.array_str(left_diagonal) or check in np.array_str(right_diagonal):\n",
    "                self.isDone = True\n",
    "        \n",
    "        if self.isDone:\n",
    "            return self.reward['win']\n",
    "        # check for draw\n",
    "        elif np.sum([self.board_state == 0]) == 0:\n",
    "            self.isDone = True\n",
    "            return self.reward['draw']\n",
    "        else:\n",
    "            return 0.\n",
    "        \n",
    "    def make_move(self, a, player):\n",
    "        # check if move is valid\n",
    "        if a in self.get_available_actions():\n",
    "            i = np.sum([self.board_state[:, a] == 0]) - 1\n",
    "            self.board_state[i, a] = self.players[player]\n",
    "        else:\n",
    "            print('Move is invalid')\n",
    "            self.render()\n",
    "\n",
    "        reward = self.check_game_done(player)\n",
    "        \n",
    "        # give feedback as new state and reward\n",
    "        return self.board_state.copy(), reward\n",
    "\n",
    "env = connect_x()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aWUNAhJQX7Rs"
   },
   "source": [
    "# Experience replay\n",
    "\n",
    "We’ll be using experience replay for training our DQN. It stores the transitions that the agent observes, allowing us to reuse this data later. By sampling from it randomly, the transitions that build up a batch are decorrelated. It has been shown that this greatly stabilizes and improves the DQN training procedure.  \n",
    "\n",
    "For a brief review of more advanced sampling algorithm mentioned in AlphaGo zero, its sampling procedure can be divided into 3 phases.\n",
    "\n",
    "* Optimization:\n",
    "      It checkpoints the deep learning agent by recording its weights every 1000 training iterations. \n",
    "* Evaluation:\n",
    "      Evaluate the checkpoints model by letting the two playing against each other for 400 games, the one wins > 55% will become the current best model (with epsilon = 0 = no exploration). \n",
    "* Self-play: \n",
    "      They will only use the current best model or player to generate training data for the optimization step.  \n",
    "\n",
    "For a more deep dive of the AlphaGo zero's impressive algorithm, readers can refer to the <a href=\"https://discovery.ucl.ac.uk/id/eprint/10045895/1/agz_unformatted_nature.pdf\">original paper</a> or this post - <a href=\"https://medium.com/@jonathan_hui/alphago-zero-a-game-changer-14ef6e45eba5\">AlphaGo Zero — a game changer</a>, the author did a great job of summarizing the details from MCTS, ResNet to self-playing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iKWkZ7PQX7Ru"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "# memory block for deep q learning\n",
    "class replayMemory:\n",
    "    def __init__(self):\n",
    "        self.memory = []\n",
    "        \n",
    "    def dump(self, transition_tuple):\n",
    "        self.memory.append(transition_tuple)\n",
    "    \n",
    "    def sample(self, batch_size):\n",
    "        return random.sample(self.memory, batch_size)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.memory)\n",
    "    \n",
    "memory = replayMemory()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qwM5WA4YX7Rx"
   },
   "source": [
    "# Deep Q-network\n",
    "\n",
    "Our model will be using a convolutional neural network that takes into the state as an image of board_state and output the state action function value for all states. In effect, the network is trying to predict the expected return of taking each action given the current input. But be aware that, the game's action space is changing so agent can only take legal actions.  \n",
    "\n",
    "More advanced way to deal with training a better function approximator for fully observation games like Go and Connect-4 is to preprocess input images. AlphaGo zero separated the training input image into two binary matrix of 0 and 1s made by white and black stones. Also, to handle strategic moves better, it includes the history (last 8 moves of game) as input, plus 1 extra dimension as 0 or 1 indicating whether it is the players turn to make a move, in their case, the input is therfore 19 \\* 19 \\* 17 (2 * 8 + 1) image vector. The output is a policy vector of 19 \\* 19 (the probabilities of making a moves) and a state value scalar.  \n",
    "\n",
    "For fast experimentation, our DQN will just use a single image map as 6 \\* 7 \\* 1 with 1 as the moves made by player 1 and 2 as the moves made by player 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dvg8TvDeX7Ry"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class DQN(nn.Module):\n",
    "    \n",
    "    def __init__(self, outputs):\n",
    "        super(DQN, self).__init__()\n",
    "        # 6 by 7, 10 by 11 \n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=5, padding=2)\n",
    "        self.conv2 = nn.Conv2d(32, 32, kernel_size=5, padding=2)\n",
    "        self.conv3 = nn.Conv2d(32, 32, kernel_size=5, padding=2)\n",
    "        self.conv4 = nn.Conv2d(32, 32, kernel_size=5, padding=2)\n",
    "        self.conv5 = nn.Conv2d(32, 32, kernel_size=5, padding=2)\n",
    "        self.conv6 = nn.Conv2d(32, 32, kernel_size=5, padding=2)\n",
    "        self.conv7 = nn.Conv2d(32, 32, kernel_size=5, padding=2)\n",
    "\n",
    "        linear_input_size = 6 * 7 * 32\n",
    "        self.MLP1 = nn.Linear(linear_input_size, 50)\n",
    "        self.MLP2 = nn.Linear(50, 50)\n",
    "        self.MLP3 = nn.Linear(50, 50)\n",
    "        self.MLP4 = nn.Linear(50, outputs)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.leaky_relu(self.conv1(x))\n",
    "        x = F.leaky_relu(self.conv2(x))\n",
    "        x = F.leaky_relu(self.conv3(x))\n",
    "        x = F.leaky_relu(self.conv4(x))\n",
    "        x = F.leaky_relu(self.conv5(x))\n",
    "        x = F.leaky_relu(self.conv6(x))\n",
    "        x = F.leaky_relu(self.conv7(x))\n",
    "        # flatten the feature vector except batch dimension\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = F.leaky_relu(self.MLP1(x))\n",
    "        x = F.leaky_relu(self.MLP2(x))\n",
    "        x = F.leaky_relu(self.MLP3(x))\n",
    "        return self.MLP4(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OzyS9e3yX7R1"
   },
   "source": [
    "# Agent\n",
    "Below created 2 models of the same DQN object, termed as target_net and policy_net. The creation of 2 nets instead of 1 is to stablilize the training by a lagged goal provided by target_net. The reasonale behind this will be explained more in the \"Optimizing policy\" section.  \n",
    "\n",
    "To accelerate training with at least 100x, below uses the free CPU provided by Google Colab. To use GPU in Pytorch, first is setting the CUDA device, then send the model, input and output tensors to GPU memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "wrei1Lf2lIaA",
    "outputId": "9d7f39c7-47b7-4f4e-d235-0888025c87f8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "# Assuming that we are on a CUDA machine, this should print a CUDA device:\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 294
    },
    "colab_type": "code",
    "id": "AHTx0X7TQqIU",
    "outputId": "83dd9de8-ad56-41cb-a2c9-1fdee05bad35"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# epilson decay graph\n",
    "EPS_START = 0.9\n",
    "EPS_END = 0.05\n",
    "EPS_DECAY = 2000\n",
    "\n",
    "steps_done = np.arange(20000)\n",
    "eps = EPS_END + (EPS_START - EPS_END) * np.exp(-1 * steps_done / EPS_DECAY)\n",
    "plt.plot(steps_done, eps)\n",
    "plt.title('Epsilon decay graph')\n",
    "plt.xlabel('Episode no.')\n",
    "plt.ylabel('Epsilon')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yeZYuoVWX7R2"
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "import math\n",
    "\n",
    "BATCH_SIZE = 256\n",
    "GAMMA = 0.999\n",
    "\n",
    "# get max no. of actions from action space\n",
    "n_actions = env.board_width\n",
    "\n",
    "height = env.board_height\n",
    "width = env.board_width\n",
    "\n",
    "policy_net = DQN(n_actions).to(device)\n",
    "# target_net will be updated every n episodes to tell policy_net a better estimate of how far off from convergence\n",
    "target_net = DQN(n_actions).to(device)\n",
    "target_net.load_state_dict(policy_net.state_dict())\n",
    "# set target_net in testing mode\n",
    "target_net.eval()\n",
    "\n",
    "optimizer = optim.Adam(policy_net.parameters())\n",
    "\n",
    "def select_action(state, available_actions, steps_done=None, training=True):\n",
    "    # batch and color channel\n",
    "    state = torch.tensor(state, dtype=torch.float, device=device).unsqueeze(dim=0).unsqueeze(dim=0)\n",
    "    epsilon = random.random()\n",
    "    if training:\n",
    "        eps_threshold = EPS_END + (EPS_START - EPS_END) * math.exp(-1 * steps_done / EPS_DECAY)\n",
    "    else:\n",
    "        eps_threshold = 0\n",
    "    \n",
    "    # follow epsilon-greedy policy\n",
    "    if epsilon > eps_threshold:\n",
    "        with torch.no_grad():\n",
    "            # action recommendations from policy net\n",
    "            r_actions = policy_net(state)[0, :]\n",
    "            state_action_values = [r_actions[action] for action in available_actions]\n",
    "            argmax_action = np.argmax(state_action_values)\n",
    "            greedy_action = available_actions[argmax_action]\n",
    "            return greedy_action\n",
    "    else:\n",
    "        return random.choice(available_actions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "U1-MMBuSX7R6"
   },
   "source": [
    "# Optmizing policy\n",
    "\n",
    "Now, let's define our model. But first, let quickly recap what a DQN is.\n",
    "\n",
    "Model based environment is deterministic, but model-free is not.\n",
    "Our aim will be to train a policy that tries to maximize the discounted,\n",
    "cumulative reward\n",
    "$R_{t_0} = \\sum_{t=t_0}^{\\infty} \\gamma^{t - t_0} r_t$, where\n",
    "$R_{t_0}$ is also known as the *return*. The discount,\n",
    "$\\gamma$, should be a constant between $0$ and $1$\n",
    "that ensures the sum converges. It makes rewards from the uncertain far\n",
    "future less important for our agent than the ones in the near future\n",
    "that it can be fairly confident about.\n",
    "\n",
    "The main idea behind Q-learning is that if we had a function\n",
    "$Q^*: State \\times Action \\rightarrow \\mathbb{R}$, that could tell\n",
    "us what our return would be, if we were to take an action in a given\n",
    "state, then we could easily construct a policy that maximizes our\n",
    "rewards:\n",
    "\n",
    "\\begin{align}\\pi^*(s) = \\arg\\!\\max_a \\ Q^*(s, a)\\end{align}\n",
    "\n",
    "However, we don't know everything about the world, so we don't have\n",
    "access to $Q^*$. But, since neural networks are universal function\n",
    "approximators, we can simply create one and train it to resemble\n",
    "$Q^*$.\n",
    "\n",
    "For our training update rule, we'll use a fact that every $Q$\n",
    "function for a optimal policy in a Markov Decision Process obeys the Bellman optimality equation:\n",
    "\n",
    "\\begin{align}Q^{\\pi}(s, a) = \\mathbb{E}_{(s, a, s', r)}  r + \\gamma Q^{\\pi}(s', \\pi(s'))\\end{align}\n",
    "\n",
    "In the training of a Deep Q network, the RHS is the 'Prediction' from policy_net, the LHS is the 'Truth' from target_net.\n",
    "The difference between the two sides of the equality is known as the\n",
    "temporal difference error, $\\delta$:\n",
    "\n",
    "\\begin{align}\\delta = Q(s, a) - (r + \\gamma \\max_a Q(s', a))\\end{align}\n",
    "\n",
    "To minimise this error, we will use the [Huber\n",
    "loss](https://en.wikipedia.org/wiki/Huber_loss). The Huber loss acts\n",
    "like the mean squared error when the error is small, but like the mean\n",
    "absolute error when the error is large - this makes it more robust to\n",
    "outliers when the estimates of $Q$ are very noisy. We calculate\n",
    "this over a batch of transitions, $B$, sampled from the replay\n",
    "memory:\n",
    "\n",
    "\\begin{align}\\mathcal{L} = \\frac{1}{|B|}\\sum_{(s, a, s', r) \\ \\in \\ B} \\mathcal{L}(\\delta)\\end{align}\n",
    "\n",
    "\\begin{align}\\text{where} \\quad \\mathcal{L}(\\delta) = \\begin{cases}\n",
    "     \\frac{1}{2}{\\delta^2}  & \\text{for } |\\delta| \\le 1, \\\\\n",
    "     |\\delta| - \\frac{1}{2} & \\text{otherwise.}\n",
    "   \\end{cases}\\end{align}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qsda1nDIX7R7"
   },
   "outputs": [],
   "source": [
    "def optimize_model():\n",
    "    if len(memory) < BATCH_SIZE:\n",
    "        return\n",
    "    transitions = memory.sample(BATCH_SIZE)\n",
    "    state_batch, action_batch, reward_batch, next_state_batch = zip(*[(np.expand_dims(m[0], axis=0), \\\n",
    "                                        [m[1]], m[2], np.expand_dims(m[3], axis=0)) for m in transitions])\n",
    "    # tensor wrapper\n",
    "    state_batch = torch.tensor(state_batch, dtype=torch.float, device=device)\n",
    "    action_batch = torch.tensor(action_batch, dtype=torch.long, device=device)\n",
    "    reward_batch = torch.tensor(reward_batch, dtype=torch.float, device=device)\n",
    "    \n",
    "    # for assigning terminal state value = 0 later\n",
    "    non_final_mask = torch.tensor(tuple(map(lambda s_: s_[0] is not None, next_state_batch)), device=device)\n",
    "    non_final_next_state = torch.cat([torch.tensor(s_, dtype=torch.float, device=device).unsqueeze(0) for s_ in next_state_batch if s_[0] is not None])\n",
    "    \n",
    "    # prediction from policy_net\n",
    "    state_action_values = policy_net(state_batch).gather(1, action_batch)\n",
    "    \n",
    "    # truth from target_net, initialize with zeros since terminal state value = 0\n",
    "    next_state_values = torch.zeros(BATCH_SIZE, device=device)\n",
    "    # tensor.detach() creates a tensor that shares storage with tensor that does not require grad\n",
    "    next_state_values[non_final_mask] = target_net(non_final_next_state).max(1)[0].detach()\n",
    "    # compute the expected Q values\n",
    "    expected_state_action_values = (next_state_values * GAMMA) + reward_batch\n",
    "\n",
    "    # Compute Huber loss\n",
    "    loss = F.smooth_l1_loss(state_action_values, expected_state_action_values.unsqueeze(1)) # torch.tensor.unsqueeze returns a copy\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QijTPOP7X7R_"
   },
   "source": [
    "# Training loop\n",
    "Our agent (policy_net) will play against random agent, as a baby step, it will learn how to play and win the game at a beginner level. The agent is expected to perform better than ignorance player at the end of episodes. In short, the student is expected to outperform the teacher. It is the sole goal of training.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wv7bfwIUX7SA"
   },
   "outputs": [],
   "source": [
    "# random agent\n",
    "def random_agent(actions):\n",
    "    return random.choice(actions)\n",
    "\n",
    "# win rate test\n",
    "def win_rate_test():\n",
    "    win_moves_taken_list = []\n",
    "    win = []\n",
    "    for i in range(100):\n",
    "        env.reset()\n",
    "        win_moves_taken = 0\n",
    "\n",
    "        while not env.isDone:\n",
    "            state = env.board_state.copy()\n",
    "            available_actions = env.get_available_actions()\n",
    "            action = select_action(state, available_actions, training=False)\n",
    "            state, reward = env.make_move(action, 'p1')\n",
    "            win_moves_taken += 1\n",
    "\n",
    "            if reward == 1:\n",
    "                win_moves_taken_list.append(win_moves_taken)\n",
    "                win.append(1)\n",
    "                break\n",
    "\n",
    "            available_actions = env.get_available_actions()\n",
    "            action = random_agent(available_actions)\n",
    "            state, reward = env.make_move(action, 'p2')\n",
    "\n",
    "    return sum(win)/100, sum(win_moves_taken_list)/len(win_moves_taken_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "seVugEMRX7SG"
   },
   "outputs": [],
   "source": [
    "# avoid resetting\n",
    "steps_done = 0\n",
    "training_history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "uSlCL75vX7SK",
    "outputId": "6033066d-b3db-49ce-b1a9-b2bb2a586c4d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete\n"
     ]
    }
   ],
   "source": [
    "from itertools import count\n",
    "\n",
    "num_episodes = 20000\n",
    "# control how lagged is target network by updating every n episodes\n",
    "TARGET_UPDATE = 10\n",
    "\n",
    "for i in range(num_episodes): \n",
    "    env.reset()\n",
    "    state_p1 = env.board_state.copy()\n",
    "\n",
    "    # record every 20 epochs\n",
    "    if i % 20 == 19:\n",
    "        win_rate, moves_taken = win_rate_test()\n",
    "        training_history.append([i + 1, win_rate, moves_taken])\n",
    "        th = np.array(training_history)\n",
    "        # print training message every 200 epochs\n",
    "        if i % 200 == 199:\n",
    "            print('Episode {}: | win_rate: {} | moves_taken: {}'.format(i, th[-1, 1], th[-1, 2]))\n",
    "\n",
    "    for t in count():\n",
    "        available_actions = env.get_available_actions()\n",
    "        action_p1 = select_action(state_p1, available_actions, steps_done)\n",
    "        steps_done += 1\n",
    "        state_p1_, reward_p1 = env.make_move(action_p1, 'p1')\n",
    "        \n",
    "        if env.isDone:\n",
    "            if reward_p1 == 1:\n",
    "                # reward p1 for p1's win\n",
    "                memory.dump([state_p1, action_p1, 1, None])\n",
    "            else:\n",
    "                # state action value tuple for a draw\n",
    "                memory.dump([state_p1, action_p1, 0.5, None])\n",
    "            break\n",
    "        \n",
    "        available_actions = env.get_available_actions()\n",
    "        action_p2 = random_agent(available_actions)\n",
    "        state_p2_, reward_p2 = env.make_move(action_p2, 'p2')\n",
    "        \n",
    "        if env.isDone:\n",
    "            if reward_p2 == 1:\n",
    "                # punish p1 for (random agent) p2's win \n",
    "                memory.dump([state_p1, action_p1, -1, None])\n",
    "            else:\n",
    "                # state action value tuple for a draw\n",
    "                memory.dump([state_p1, action_p1, 0.5, None])\n",
    "            break\n",
    "        \n",
    "        # punish for taking too long to win\n",
    "        memory.dump([state_p1, action_p1, -0.05, state_p2_])\n",
    "        state_p1 = state_p2_\n",
    "        \n",
    "        # Perform one step of the optimization (on the policy network)\n",
    "        optimize_model()\n",
    "        \n",
    "    # update the target network, copying all weights and biases in DQN\n",
    "    if i % TARGET_UPDATE == TARGET_UPDATE - 1:\n",
    "        target_net.load_state_dict(policy_net.state_dict())\n",
    "\n",
    "print('Complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 556
    },
    "colab_type": "code",
    "id": "ONshTG-y3A0P",
    "outputId": "6406e403-c6f5-47e4-ee76-dcbc9fda69ac"
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "too many indices for array: array is 0-dimensional, but 2 were indexed",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 38\u001b[0m\n\u001b[0;32m     36\u001b[0m win_rate_moving_average \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([(i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m19\u001b[39m) \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m20\u001b[39m, np\u001b[38;5;241m.\u001b[39mmean(th[i: i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m20\u001b[39m, \u001b[38;5;241m1\u001b[39m])] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(th) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m19\u001b[39m))\n\u001b[0;32m     37\u001b[0m win_rate_moving_average \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(win_rate_moving_average\u001b[38;5;241m.\u001b[39mtolist())  \u001b[38;5;66;03m# Convert to 2D array\u001b[39;00m\n\u001b[1;32m---> 38\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(\u001b[43mwin_rate_moving_average\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m, win_rate_moving_average[:, \u001b[38;5;241m1\u001b[39m], c\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmoving average of win rate\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     39\u001b[0m plt\u001b[38;5;241m.\u001b[39mlegend()\n\u001b[0;32m     40\u001b[0m plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPlaying against random agent\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mIndexError\u001b[0m: too many indices for array: array is 0-dimensional, but 2 were indexed"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"plt.plot(th[:, 0], th[:, 1], c='c')\n",
    "win_rate_moving_average = np.array([[(i + 19) * 20, np.mean(th[i: i + 20, 1])] for i in range(len(th) - 19)])\n",
    "plt.plot(win_rate_moving_average[:, 0], win_rate_moving_average[:, 1], c='b', label='moving average of win rate')\n",
    "plt.legend()\n",
    "plt.title('Playing against random agent')\n",
    "plt.xlabel('Episode no.')\n",
    "plt.ylabel('Win rate')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(th[:, 0], th[:, 2], c='c')\n",
    "win_steps_taken_moving_average = np.array([[(i + 19) * 20, np.mean(th[i: i + 20, 2])] for i in range(len(th) - 19)])\n",
    "plt.plot(win_steps_taken_moving_average[:, 0], win_steps_taken_moving_average[:, 1], c='b', label='moving average of win steps taken')\n",
    "plt.legend()\n",
    "plt.xlabel('Episode no.')\n",
    "plt.ylabel('Average steps taken for a win')\n",
    "plt.show()\"\"\"\n",
    "\n",
    "\"\"\"plt.plot(th[:, 0], th[:, 1], c='c')\n",
    "win_rate_moving_average = np.array([[(i + 19) * 20, np.mean(th[i: i + 20, 1])] for i in range(len(th) - 19)])\n",
    "plt.plot(win_rate_moving_average[:, 0], win_rate_moving_average[:, 1], c='b', label='moving average of win rate')\n",
    "plt.legend()\n",
    "plt.title('Playing against random agent')\n",
    "plt.xlabel('Episode no.')\n",
    "plt.ylabel('Win rate')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(th[:, 0], th[:, 2], c='c')\n",
    "win_steps_taken_moving_average = np.array([[(i + 19) * 20, np.mean(th[i: i + 20, 2])] for i in range(len(th) - 19)])\n",
    "plt.plot(win_steps_taken_moving_average[:, 0], win_steps_taken_moving_average[:, 1], c='b', label='moving average of win steps taken')\n",
    "plt.legend()\n",
    "plt.xlabel('Episode no.')\n",
    "plt.ylabel('Average steps taken for a win')\n",
    "plt.show()\"\"\"\n",
    "\n",
    "plt.plot(th[:, 0], th[:, 1], c='c')\n",
    "win_rate_moving_average = np.array([(i + 19) * 20, np.mean(th[i: i + 20, 1])] for i in range(len(th) - 19))\n",
    "win_rate_moving_average = np.array(win_rate_moving_average.tolist())  # Convert to 2D array\n",
    "plt.plot(win_rate_moving_average[:, 0], win_rate_moving_average[:, 1], c='b', label='moving average of win rate')\n",
    "plt.legend()\n",
    "plt.title('Playing against random agent')\n",
    "plt.xlabel('Episode no.')\n",
    "plt.ylabel('Win rate')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(th[:, 0], th[:, 2], c='c')\n",
    "win_steps_taken_moving_average = np.array([(i + 19) * 20, np.mean(th[i: i + 20, 2])] for i in range(len(th) - 19))\n",
    "win_steps_taken_moving_average = np.array(win_steps_taken_moving_average.tolist())  # Convert to 2D array\n",
    "plt.plot(win_steps_taken_moving_average[:, 0], win_steps_taken_moving_average[:, 1], c='b', label='moving average of win steps taken')\n",
    "plt.legend()\n",
    "plt.xlabel('Episode no.')\n",
    "plt.ylabel('Average steps taken for a win')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "d9QMIgxZRi8h"
   },
   "source": [
    "As one can see from the graph above, \n",
    "* The variance of win rate is getting smaller and the moving average for win rate is also getting higher. \n",
    "* The average win steps taken has gone down, which means the agent has learnt to win as fast as possible.\n",
    "\n",
    "Both are the indication of the fact that our agent has learnt how to win Connect 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qSftrJqS6SyX"
   },
   "outputs": [],
   "source": [
    "path = 'DQN_plainCNN.pth'\n",
    "torch.save(policy_net.state_dict(), path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "inAIRHSbDKfa"
   },
   "source": [
    "# Demonstration of a trained agent playing a game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "1EqVMrz39bJe",
    "outputId": "17e74110-a6a2-445a-b45b-e0437595b623"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_3388\\1160232653.py:16: FutureWarning: In the future `np.str` will be defined as the corresponding NumPy scalar.\n",
      "  rendered_board_state = self.board_state.copy().astype(np.str)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'numpy' has no attribute 'str'.\n`np.str` was a deprecated alias for the builtin `str`. To avoid this error in existing code, use `str` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.str_` here.\nThe aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:\n    https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 21\u001b[0m\n\u001b[0;32m     18\u001b[0m         state, reward \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mmake_move(action, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mp2\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     19\u001b[0m         env\u001b[38;5;241m.\u001b[39mrender()\n\u001b[1;32m---> 21\u001b[0m \u001b[43mdemo\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[23], line 3\u001b[0m, in \u001b[0;36mdemo\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdemo\u001b[39m():\n\u001b[0;32m      2\u001b[0m     env\u001b[38;5;241m.\u001b[39mreset()\n\u001b[1;32m----> 3\u001b[0m     \u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrender\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m env\u001b[38;5;241m.\u001b[39misDone:\n\u001b[0;32m      6\u001b[0m         state \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mboard_state\u001b[38;5;241m.\u001b[39mcopy()\n",
      "Cell \u001b[1;32mIn[1], line 16\u001b[0m, in \u001b[0;36mconnect_x.render\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrender\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m---> 16\u001b[0m     rendered_board_state \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mboard_state\u001b[38;5;241m.\u001b[39mcopy()\u001b[38;5;241m.\u001b[39mastype(\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstr\u001b[49m)\n\u001b[0;32m     17\u001b[0m     rendered_board_state[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mboard_state \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     18\u001b[0m     rendered_board_state[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mboard_state \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mO\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\numpy\\__init__.py:338\u001b[0m, in \u001b[0;36m__getattr__\u001b[1;34m(attr)\u001b[0m\n\u001b[0;32m    333\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    334\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIn the future `np.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mattr\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m` will be defined as the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    335\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcorresponding NumPy scalar.\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;167;01mFutureWarning\u001b[39;00m, stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m    337\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m attr \u001b[38;5;129;01min\u001b[39;00m __former_attrs__:\n\u001b[1;32m--> 338\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(__former_attrs__[attr])\n\u001b[0;32m    340\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m attr \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtesting\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    341\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtesting\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtesting\u001b[39;00m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'numpy' has no attribute 'str'.\n`np.str` was a deprecated alias for the builtin `str`. To avoid this error in existing code, use `str` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.str_` here.\nThe aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:\n    https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations"
     ]
    }
   ],
   "source": [
    "def demo():\n",
    "    env.reset()\n",
    "    env.render()\n",
    "\n",
    "    while not env.isDone:\n",
    "        state = env.board_state.copy()\n",
    "        available_actions = env.get_available_actions()\n",
    "        action = select_action(state, available_actions, training=False)\n",
    "        # trained agent's move is denoted by O\n",
    "        state, reward = env.make_move(action, 'p1')\n",
    "        env.render()\n",
    "\n",
    "        if reward == 1:\n",
    "            break\n",
    "\n",
    "        available_actions = env.get_available_actions()\n",
    "        action = random_agent(available_actions)\n",
    "        state, reward = env.make_move(action, 'p2')\n",
    "        env.render()\n",
    "\n",
    "demo()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bZwPms8h9bQP"
   },
   "source": [
    "From the above gameplay, the agent (denoted by O) knows putting in (5, 1) is a winning move even after its original strategy is blocked by p2 in step 5 by putting X in (3, 2)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "connect X.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
